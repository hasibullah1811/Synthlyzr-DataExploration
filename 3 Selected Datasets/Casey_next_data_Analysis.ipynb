{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed985c77-b20d-45a1-8966-72ec2251a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hasibullah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hasibullah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hasibullah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b911f4-62e9-4501-baca-9486338cf5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = 'casey-next-data-short-survey.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    # If utf-8 fails, use a fallback encoding\n",
    "    df = pd.read_csv(file_path, encoding='latin1')  # Common fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7c3ab-ae33-4d1c-a5f6-51df88f9da64",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03f4f3-0d79-48a3-aedb-9e208b5e979c",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956e4fb2-10a1-4723-828b-e445d1d1089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of place would you like Casey to be in 2041?                                    17\n",
      "If you had the power to change just one thing in the City of Casey what would it be?      36\n",
      "What three words would you use to describe your Vision for the City of Casey?            124\n",
      "Unnamed: 3                                                                               400\n",
      "Unnamed: 4                                                                               642\n",
      "What's most important to you?                                                           1580\n",
      "Other                                                                                   2414\n",
      "What is your suburb?                                                                      14\n",
      "Postcode                                                                                 688\n",
      "Ward                                                                                       5\n",
      "What is your age?                                                                         56\n",
      "What is your Gender                                                                       77\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# replacing missing text entries with an empty string\n",
    "text_columns = [\n",
    "    'What kind of place would you like Casey to be in 2041?',\n",
    "    'If you had the power to change just one thing in the City of Casey what would it be?',\n",
    "    'What three words would you use to describe your Vision for the City of Casey?',\n",
    "    'What\\'s most important to you?',\n",
    "    'Other'\n",
    "]\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].fillna('')\n",
    "\n",
    "# Drop rows with missing demographic data if necessary\n",
    "df.dropna(subset=['What is your suburb?', 'Postcode', 'Ward', 'What is your age?', 'What is your Gender'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b5477-ae7e-4f26-badf-c6f846be99dd",
   "metadata": {},
   "source": [
    "## Normalize Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0048df46-dc3a-41dd-ba44-0b3aecb81faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce91a1-9abc-464d-a2ef-650e65ce53a7",
   "metadata": {},
   "source": [
    "# Text Pre-processing\n",
    "## Define Pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b923898c-4ae8-4d22-8391-00dec59542a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLP tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Join tokens back into string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186a1ce-5493-49d6-9aed-c29583fc1577",
   "metadata": {},
   "source": [
    "## Apply the pr-processing function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3762beff-4dac-4165-b5d9-53f8bdaf6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_columns:\n",
    "    df[col] = df[col].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9886a-3560-4d79-9381-e1e8605650d1",
   "metadata": {},
   "source": [
    "## Concatenate Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74bd15e3-1393-4c3e-82bc-7bc9550b975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all text fields into one column\n",
    "df['combined_text'] = df[text_columns].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a654fb-81ef-4f05-82e0-bc71c7dcb449",
   "metadata": {},
   "source": [
    "## Prepare Data for LLM Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d9f8c8-3582-41a2-97ba-fe5d65050d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined text to a file\n",
    "output_file = 'casey_next_pretraining_corpus.txt'\n",
    "\n",
    "# Write to file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for text in df['combined_text']:\n",
    "        f.write(text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "584e36b6-762e-41fe-93bf-980b33db35ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the pretraining corpus: 1757\n"
     ]
    }
   ],
   "source": [
    "# Check the number of lines written\n",
    "num_lines = sum(1 for line in open(output_file, 'r', encoding='utf-8'))\n",
    "print(f\"Number of lines in the pretraining corpus: {num_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1b01dd-2056-4ddc-a1e0-4e44e535fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to a separate file\n",
    "metadata = df[['What is your suburb?', 'Postcode', 'Ward', 'What is your age?', 'What is your Gender']]\n",
    "metadata.to_csv('casey_next_metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7765b6-6382-4427-b3a0-5930de9fc5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
